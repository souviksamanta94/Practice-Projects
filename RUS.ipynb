{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calculating loss and confusion matrix\n",
    "def binary_loss(y, y_predict, fp_cost, fn_cost, display=True):\n",
    "    loss = [0, 0] #False Neg Cost, False Pos Cost\n",
    "    conf_mat = [0, 0, 0, 0] #tn, fp, fn, tp\n",
    "    for j in range(len(y)):\n",
    "        if y[j]==0:\n",
    "            if y_predict[j]==0:\n",
    "                conf_mat[0] += 1 #True Negative\n",
    "            else:\n",
    "                conf_mat[1] += 1 #False Positive\n",
    "                loss[1] += fp_cost[j]\n",
    "        else:\n",
    "            if y_predict[j]==1:\n",
    "                conf_mat[3] += 1 #True Positive\n",
    "            else:\n",
    "                conf_mat[2] += 1 #False Negative\n",
    "                loss[0] += fn_cost[j]\n",
    "    if display:\n",
    "        fn_loss = loss[0]\n",
    "        fp_loss = loss[1]\n",
    "        total_loss = fn_loss + fp_loss\n",
    "        misc = conf_mat[1] + conf_mat[2]\n",
    "        misc = misc/len(y)\n",
    "        print(\"{:.<23s}{:10.4f}\".format(\"Misclassification Rate\", misc))\n",
    "        print(\"{:.<23s}{:10.0f}\".format(\"False Negative Loss\", fn_loss))\n",
    "        print(\"{:.<23s}{:10.0f}\".format(\"False Positive Loss\", fp_loss))\n",
    "        print(\"{:.<23s}{:10.0f}\".format(\"Total Loss\", total_loss))\n",
    "    return loss, conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/e5/4c/7557e1c2e791bd43878f8c82065bddc5798252084f26ef44527c02262af1/imbalanced_learn-0.4.3-py3-none-any.whl (166kB)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\vasuk\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\vasuk\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\vasuk\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.4)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.4.3 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from AdvancedAnalytics import ReplaceImputeEncode, logreg, calculate\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>amount</th>\n",
       "      <th>duration</th>\n",
       "      <th>checking</th>\n",
       "      <th>coapp</th>\n",
       "      <th>depends</th>\n",
       "      <th>employed</th>\n",
       "      <th>existcr</th>\n",
       "      <th>foreign</th>\n",
       "      <th>history</th>\n",
       "      <th>housing</th>\n",
       "      <th>installp</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>other</th>\n",
       "      <th>property</th>\n",
       "      <th>resident</th>\n",
       "      <th>savings</th>\n",
       "      <th>telephon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "      <td>10500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.312667</td>\n",
       "      <td>3042.311048</td>\n",
       "      <td>19.536476</td>\n",
       "      <td>2.814000</td>\n",
       "      <td>1.140857</td>\n",
       "      <td>1.156000</td>\n",
       "      <td>3.468381</td>\n",
       "      <td>1.429524</td>\n",
       "      <td>1.046190</td>\n",
       "      <td>2.708286</td>\n",
       "      <td>1.945238</td>\n",
       "      <td>2.924095</td>\n",
       "      <td>2.896571</td>\n",
       "      <td>2.714667</td>\n",
       "      <td>2.724381</td>\n",
       "      <td>2.280571</td>\n",
       "      <td>2.855524</td>\n",
       "      <td>2.266762</td>\n",
       "      <td>1.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.366332</td>\n",
       "      <td>2484.259279</td>\n",
       "      <td>11.379256</td>\n",
       "      <td>1.246225</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>0.362873</td>\n",
       "      <td>1.197535</td>\n",
       "      <td>0.592107</td>\n",
       "      <td>0.209907</td>\n",
       "      <td>1.055895</td>\n",
       "      <td>0.497973</td>\n",
       "      <td>1.132035</td>\n",
       "      <td>0.642176</td>\n",
       "      <td>0.690729</td>\n",
       "      <td>0.660072</td>\n",
       "      <td>1.035766</td>\n",
       "      <td>1.101646</td>\n",
       "      <td>1.642080</td>\n",
       "      <td>0.493582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1366.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>2247.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>3660.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        amount      duration      checking         coapp  \\\n",
       "count  10500.000000  10500.000000  10500.000000  10500.000000  10500.000000   \n",
       "mean      36.312667   3042.311048     19.536476      2.814000      1.140857   \n",
       "std       11.366332   2484.259279     11.379256      1.246225      0.480962   \n",
       "min       19.000000    250.000000      4.000000      1.000000      1.000000   \n",
       "25%       27.000000   1366.000000     12.000000      2.000000      1.000000   \n",
       "50%       34.000000   2247.000000     18.000000      3.000000      1.000000   \n",
       "75%       42.000000   3660.000000     24.000000      4.000000      1.000000   \n",
       "max       75.000000  18424.000000     72.000000      4.000000      3.000000   \n",
       "\n",
       "            depends      employed       existcr       foreign       history  \\\n",
       "count  10500.000000  10500.000000  10500.000000  10500.000000  10500.000000   \n",
       "mean       1.156000      3.468381      1.429524      1.046190      2.708286   \n",
       "std        0.362873      1.197535      0.592107      0.209907      1.055895   \n",
       "min        1.000000      1.000000      1.000000      1.000000      0.000000   \n",
       "25%        1.000000      3.000000      1.000000      1.000000      2.000000   \n",
       "50%        1.000000      3.000000      1.000000      1.000000      2.000000   \n",
       "75%        1.000000      5.000000      2.000000      1.000000      4.000000   \n",
       "max        2.000000      5.000000      4.000000      2.000000      4.000000   \n",
       "\n",
       "            housing      installp           job       marital         other  \\\n",
       "count  10500.000000  10500.000000  10500.000000  10500.000000  10500.000000   \n",
       "mean       1.945238      2.924095      2.896571      2.714667      2.724381   \n",
       "std        0.497973      1.132035      0.642176      0.690729      0.660072   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        2.000000      2.000000      3.000000      2.000000      3.000000   \n",
       "50%        2.000000      3.000000      3.000000      3.000000      3.000000   \n",
       "75%        2.000000      4.000000      3.000000      3.000000      3.000000   \n",
       "max        3.000000      4.000000      4.000000      4.000000      3.000000   \n",
       "\n",
       "           property      resident       savings      telephon  \n",
       "count  10500.000000  10500.000000  10500.000000  10500.000000  \n",
       "mean       2.280571      2.855524      2.266762      1.420000  \n",
       "std        1.035766      1.101646      1.642080      0.493582  \n",
       "min        1.000000      1.000000      1.000000      1.000000  \n",
       "25%        1.000000      2.000000      1.000000      1.000000  \n",
       "50%        2.000000      3.000000      1.000000      1.000000  \n",
       "75%        3.000000      4.000000      4.000000      2.000000  \n",
       "max        4.000000      4.000000      5.000000      2.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'C:/Users/vasuk/Desktop/Sem 2/Stat 656/Week7/'\n",
    "df = pd.read_excel(file_path+\"CreditData_RareEvent.xlsx\")\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Changing Data Types\n",
    "df['checking']=df['checking'].astype(str)\n",
    "df['coapp']=df['coapp'].astype(str)\n",
    "df['depends']=df['depends'].astype(str)\n",
    "df['employed']=df['employed'].astype(str)\n",
    "df['existcr']=df['existcr'].astype(str)\n",
    "df['history']=df['history'].astype(str)\n",
    "df['foreign']=df['foreign'].astype(str)\n",
    "df['good_bad']=df['good_bad'].astype(str)\n",
    "df['installp']=df['installp'].astype(str)\n",
    "df['job']=df['job'].astype(str)\n",
    "df['marital']=df['marital'].astype(str)\n",
    "df['other']=df['other'].astype(str)\n",
    "df['property']=df['property'].astype(str)\n",
    "df['resident']=df['resident'].astype(str)\n",
    "df['savings']=df['savings'].astype(str)\n",
    "df['telephon']=df['telephon'].astype(str)\n",
    "df['housing']=df['housing'].astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attribute_map = {\n",
    "'age':['I', (19, 120)],\n",
    "'amount':['I', (0, 20000)],\n",
    "'checking':['N',('1','2','3','4')],\n",
    "'coapp':['N',('1', '2', '3')],\n",
    "'depends':['B',('1', '2')],\n",
    "'duration':['I',(1,72)],\n",
    "'employed':['N',('1','2','3','4','5')],\n",
    "'existcr':['N',('1','2','3','4')],\n",
    "'foreign':['B', ('1','2')],\n",
    "'good_bad':['B', ('bad','good')],\n",
    "'history':['N', ('0','1','2','3','4')],\n",
    "'housing':['N', ('1','2','3')],\n",
    "'installp':['N', ('1','2','3','4')] ,\n",
    "'job':['N', ('1','2','3','4')] ,\n",
    "'marital':['N', ('1','2','3','4')] ,\n",
    "'other':['N', ('1','2','3')] ,\n",
    "'property':['N', ('1','2','3','4')] ,\n",
    "'resident':['N', ('1','2','3','4')] ,    \n",
    "'savings':['N', ('1','2','3','4','5')] ,    \n",
    "'telephon':['B', ('1','2')] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasuk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\vasuk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\vasuk\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\vasuk\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rie=ReplaceImputeEncode(data_map=attribute_map, nominal_encoding='one-hot',interval_scale='std', drop=True, display=False)\n",
    "encoded_df = rie.fit_transform(df)\n",
    "# Create X and y, numpy arrays\n",
    "# bad=0 and good=1\n",
    "y = np.asarray(encoded_df['good_bad']) # The target is not scaled or imputed\n",
    "X = np.asarray(encoded_df.drop('good_bad',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup false positive and false negative costs for each transaction\n",
    "fp_cost = np.array(df['amount'])\n",
    "fn_cost = np.array(0.15*df['amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth= 2\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.9508    0.0047\n",
      "recall....... 0.9969    0.0047\n",
      "precision.... 0.9535    0.0016\n",
      "f1........... 0.9747    0.0025\n",
      "max_depth= 3\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.9458    0.0114\n",
      "recall....... 0.9902    0.0113\n",
      "precision.... 0.9544    0.0028\n",
      "f1........... 0.9702    0.0094\n",
      "max_depth= 4\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.9383    0.0166\n",
      "recall....... 0.9818    0.0163\n",
      "precision.... 0.9548    0.0026\n",
      "f1........... 0.9680    0.0089\n",
      "max_depth= 5\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.9327    0.0218\n",
      "recall....... 0.9748    0.0215\n",
      "precision.... 0.9555    0.0031\n",
      "f1........... 0.9658    0.0104\n",
      "max_depth= 6\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.9275    0.0247\n",
      "recall....... 0.9700    0.0241\n",
      "precision.... 0.9558    0.0033\n",
      "f1........... 0.9627    0.0130\n",
      "max_depth= 7\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.9160    0.0296\n",
      "recall....... 0.9498    0.0376\n",
      "precision.... 0.9559    0.0033\n",
      "f1........... 0.9535    0.0186\n",
      "max_depth= 8\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.9000    0.0366\n",
      "recall....... 0.9384    0.0403\n",
      "precision.... 0.9576    0.0034\n",
      "f1........... 0.9506    0.0185\n",
      "max_depth= 9\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8854    0.0420\n",
      "recall....... 0.9199    0.0381\n",
      "precision.... 0.9576    0.0025\n",
      "f1........... 0.9405    0.0188\n",
      "max_depth= 10\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8725    0.0327\n",
      "recall....... 0.8985    0.0358\n",
      "precision.... 0.9605    0.0026\n",
      "f1........... 0.9296    0.0177\n",
      "max_depth= 11\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8588    0.0343\n",
      "recall....... 0.8924    0.0349\n",
      "precision.... 0.9596    0.0027\n",
      "f1........... 0.9247    0.0174\n",
      "max_depth= 12\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8473    0.0401\n",
      "recall....... 0.8685    0.0497\n",
      "precision.... 0.9597    0.0031\n",
      "f1........... 0.9161    0.0210\n",
      "max_depth= 13\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8350    0.0505\n",
      "recall....... 0.8668    0.0457\n",
      "precision.... 0.9600    0.0035\n",
      "f1........... 0.9108    0.0281\n",
      "max_depth= 14\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8330    0.0392\n",
      "recall....... 0.8548    0.0512\n",
      "precision.... 0.9599    0.0028\n",
      "f1........... 0.9107    0.0184\n",
      "max_depth= 15\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8364    0.0411\n",
      "recall....... 0.8604    0.0492\n",
      "precision.... 0.9599    0.0032\n",
      "f1........... 0.9067    0.0286\n",
      "max_depth= 16\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8352    0.0377\n",
      "recall....... 0.8590    0.0412\n",
      "precision.... 0.9604    0.0024\n",
      "f1........... 0.9120    0.0215\n",
      "max_depth= 17\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8301    0.0412\n",
      "recall....... 0.8533    0.0510\n",
      "precision.... 0.9616    0.0030\n",
      "f1........... 0.9035    0.0285\n",
      "max_depth= 18\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8303    0.0364\n",
      "recall....... 0.8514    0.0489\n",
      "precision.... 0.9613    0.0029\n",
      "f1........... 0.9049    0.0243\n",
      "max_depth= 19\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8350    0.0417\n",
      "recall....... 0.8546    0.0538\n",
      "precision.... 0.9607    0.0035\n",
      "f1........... 0.9076    0.0213\n",
      "max_depth= 20\n",
      "Metric.......  Mean    Std. Dev.\n",
      "accuracy..... 0.8292    0.0422\n",
      "recall....... 0.8556    0.0430\n",
      "precision.... 0.9608    0.0032\n",
      "f1........... 0.9093    0.0252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#Decision Tree\n",
    "#10 fold CV with variation of depth\n",
    "score_list = ['accuracy', 'recall', 'precision', 'f1']\n",
    "search_depths = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "for d in search_depths:\n",
    "    dtc = DecisionTreeClassifier(criterion='gini', max_depth=d, min_samples_split=5, min_samples_leaf=5)\n",
    "    mean_score = []\n",
    "    std_score = []\n",
    "    print(\"max_depth=\", d)\n",
    "    print(\"{:.<13s}{:>6s}{:>13s}\".format(\"Metric\", \"Mean\", \"Std. Dev.\"))\n",
    "    for s in score_list:\n",
    "        dtc_10 = cross_val_score(dtc, X, y, scoring=s, cv=10)\n",
    "        mean = dtc_10.mean()\n",
    "        std = dtc_10.std()\n",
    "        mean_score.append(mean)\n",
    "        std_score.append(std)\n",
    "        print(\"{:.<13s}{:>7.4f}{:>10.4f}\".format(s, mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup 20 random number seeds for use in creating random samples\n",
    "np.random.seed(12345)\n",
    "max_seed = 2**10 - 1\n",
    "rand_val = np.random.randint(1, high=max_seed, size=20)\n",
    "# Ratios of Majority:Minority Events\n",
    "ratio = [ '50:50', '60:40', '75:25', '80:20', '85:15' ]\n",
    "# Dictionaries contains number of minority and majority\n",
    "# events in each ratio sample where n_majority = ratio x n_minority\n",
    "rus_ratio = ({0:500, 1:500}, {0:500, 1:750}, {0:500, 1:1167},{0:500, 1:2000}, {0:500, 1:4500})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desicion Tree Model using 50:50 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.3736\n",
      "False Negative Loss.... $ 1,842,339\n",
      "False Positive Loss.... $   505,853\n",
      "Total Loss............. $ 2,348,191 +/- $11,428\n",
      "\n",
      "Desicion Tree Model using 60:40 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.1946\n",
      "False Negative Loss.... $   921,086\n",
      "False Positive Loss.... $ 1,139,020\n",
      "Total Loss............. $ 2,060,107 +/- $27,428\n",
      "\n",
      "Desicion Tree Model using 75:25 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.1324\n",
      "False Negative Loss.... $   627,479\n",
      "False Positive Loss.... $ 1,267,242\n",
      "Total Loss............. $ 1,894,721 +/- $35,428\n",
      "\n",
      "Desicion Tree Model using 80:20 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0536\n",
      "False Negative Loss.... $   182,924\n",
      "False Positive Loss.... $ 1,541,003\n",
      "Total Loss............. $ 1,723,926 +/- $40,262\n",
      "\n",
      "Desicion Tree Model using 85:15 RUS\n",
      "Best C.................    1.00E-04\n",
      "Misclassification Rate.      0.0501\n",
      "False Negative Loss.... $   109,219\n",
      "False Positive Loss.... $ 1,648,849\n",
      "Total Loss............. $ 1,758,068 +/- $36,503\n",
      "\n",
      "Best RUS Ratio.........       80:20\n",
      "Best C.................    1.00E-04\n",
      "Lowest Loss............ $ 1,723,926 +/- $40,262\n"
     ]
    }
   ],
   "source": [
    "d=2\n",
    "# Best model is one that minimizes the loss\n",
    "c_list = [1e-4, 1e-3, 1e-2, 1e-1, 1, 2, 3, 4, 1e+64]\n",
    "min_loss = 1e64\n",
    "best_ratio = 0\n",
    "for k in range(len(rus_ratio)):\n",
    "    print(\"\\nDesicion Tree Model using \" + ratio[k] + \" RUS\")\n",
    "    best_c = 0\n",
    "    min_loss_c = 1e64\n",
    "    for j in range(len(c_list)):\n",
    "        c = c_list[j]\n",
    "        fn_loss = np.zeros(len(rand_val))\n",
    "        fp_loss = np.zeros(len(rand_val))\n",
    "        misc = np.zeros(len(rand_val))\n",
    "        for i in range(len(rand_val)):\n",
    "            rus = RandomUnderSampler(ratio=rus_ratio[k],random_state=rand_val[i],return_indices=False,replacement=False)\n",
    "            X_rus, y_rus = rus.fit_sample(X, y)\n",
    "            dtc = DecisionTreeClassifier(criterion='gini', max_depth=d, min_samples_split=5, min_samples_leaf=5)\n",
    "            dtc.fit(X_rus,y_rus)\n",
    "            loss, conf_mat = calculate.binary_loss(y,dtc.predict(X),fp_cost, fn_cost, display=False)\n",
    "            fn_loss[i] = loss[0]\n",
    "            fp_loss[i] = loss[1]\n",
    "            misc[i] = (conf_mat[1] + conf_mat[2])/y.shape[0]\n",
    "        avg_misc = np.average(misc)\n",
    "        t_loss = fp_loss+fn_loss\n",
    "        avg_loss = np.average(t_loss)\n",
    "        if avg_loss < min_loss_c:\n",
    "            min_loss_c = avg_loss\n",
    "            se_loss_c = np.std(t_loss)/math.sqrt(len(rand_val))\n",
    "            best_c = c\n",
    "            misc_c = avg_misc\n",
    "            fn_avg_loss = np.average(fn_loss)\n",
    "            fp_avg_loss = np.average(fp_loss)\n",
    "    if min_loss_c < min_loss:\n",
    "        min_loss = min_loss_c\n",
    "        se_loss = se_loss_c\n",
    "        best_ratio = k\n",
    "        best_reg = best_c\n",
    "    print(\"{:.<23s}{:12.2E}\".format(\"Best C\", best_c))\n",
    "    print(\"{:.<23s}{:12.4f}\".format(\"Misclassification Rate\",misc_c))\n",
    "    print(\"{:.<23s} ${:10,.0f}\".format(\"False Negative Loss\",fn_avg_loss))\n",
    "    print(\"{:.<23s} ${:10,.0f}\".format(\"False Positive Loss\",fp_avg_loss))\n",
    "    print(\"{:.<23s} ${:10,.0f}{:5s}${:<,.0f}\".format(\"Total Loss\",min_loss_c, \" +/- \", se_loss_c))\n",
    "print(\"\")\n",
    "print(\"{:.<23s}{:>12s}\".format(\"Best RUS Ratio\", ratio[best_ratio]))\n",
    "print(\"{:.<23s}{:12.2E}\".format(\"Best C\", best_reg))\n",
    "print(\"{:.<23s} ${:10,.0f}{:5s}${:<,.0f}\".format(\"Lowest Loss\", min_loss, \" +/-\", se_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Estimates based on averaging 100 Models\n",
      "Misclassification Rate.    0.0544\n",
      "False Negative Loss....    219420\n",
      "False Positive Loss....   1366692\n",
      "Total Loss.............   1586112\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Modeling - Averaging Classification Probabilities\n",
    "n_obs = len(y)\n",
    "n_rand = 100\n",
    "predicted_prob = np.zeros((n_obs,n_rand))\n",
    "avg_prob = np.zeros(n_obs)\n",
    "# Setup 100 random number seeds for use in creating random samples\n",
    "np.random.seed(12345)\n",
    "max_seed = 2**10 - 1\n",
    "rand_value = np.random.randint(1, high=max_seed, size=n_rand)\n",
    "# Model 100 random samples, each with a 70:30 ratio\n",
    "for i in range(len(rand_value)):\n",
    "    rus = RandomUnderSampler(ratio=rus_ratio[best_ratio],random_state=rand_value[i], return_indices=False,replacement=False)\n",
    "    X_rus, y_rus = rus.fit_sample(X, y)\n",
    "    dtc = DecisionTreeClassifier(criterion='gini', max_depth=d, min_samples_split=5, min_samples_leaf=5)\n",
    "    dtc.fit(X_rus,y_rus)\n",
    "    predicted_prob[0:n_obs, i] = dtc.predict_proba(X)[0:n_obs, 0]\n",
    "\n",
    "for i in range(n_obs):\n",
    "    avg_prob[i] = np.mean(predicted_prob[i,0:n_rand])\n",
    "# Set y_pred equal to the predicted classification\n",
    "y_pred = avg_prob[0:n_obs] < 0.5\n",
    "y_pred.astype(np.int)\n",
    "# Calculate loss from using the ensemble predictions\n",
    "print(\"\\nEnsemble Estimates based on averaging\",len(rand_value), \"Models\")\n",
    "loss, conf_mat = calculate.binary_loss(y, y_pred, fp_cost, fn_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
